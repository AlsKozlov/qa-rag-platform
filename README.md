# QA-RAG-Platform

**QA-RAG-Platform** — это open-source платформа для реализации Retrieval-Augmented Generation (RAG) систем, позволяющая отвечать на вопросы пользователей на основе поиска и генерации ответов из собственной базы знаний.

---

## Основные возможности

- **Retrieval** — быстрый поиск релевантных документов или фрагментов текста (bi-encoder/cross-encoder).
- **Augmentation** — обогащение контекста найденными результатами для генерации ответа.
- **Generation** — генерация ответов с использованием LLM.
- **DVC** — управление данными и моделями.
- **Docker Compose** — контейнеризация для удобного запуска сервисов.
- **Airflow** — автоматизация пайплайнов данных и обучения.
- **CI/CD** — готовая интеграция с GitLab CI (с возможностью адаптации под GitHub Actions).

---

## Структура проекта

```
qa-rag-platform/
│
├── rag-api-service/         # Основной сервис API для RAG
│   ├── app/                 # Логика приложения (FastAPI)
│   ├── routers/             # Эндпоинты API
│   ├── services/            # Сервисы для работы с LLM и данными
│   ├── database/            # Настройка БД
│   ├── elastic/             # Интеграция с Elasticsearch
│   ├── workers/             # Очереди и обработчики задач
│   └── Dockerfile           # Контейнеризация сервиса
│
├── sft-pipeline/            # Пайплайны обучения и обработки данных (Airflow DAGs)
│   └── dags/services/       # Модули пайплайнов
│
├── .gitlab-ci.yml           # Конфигурация CI/CD для GitLab
├── docker-compose.yml       # Общий запуск через Docker Compose (по желанию)
├── data.dvc                 # DVC: управление данными
├── model.dvc                # DVC: управление моделями
└── README.md                # Этот файл
```

---

## Быстрый старт

### 1. Клонировать репозиторий

```bash
git clone https://github.com/yourusername/qa-rag-platform.git
cd qa-rag-platform
```

### 2. Установить зависимости

Убедитесь, что у вас установлены Docker и Docker Compose.

```bash
docker-compose up --build
```

**Важно**: Каждый сервис (например, `rag-api-service`) имеет свой собственный Dockerfile (и при необходимости — Docker Compose) внутри папки сервиса. Для запуска отдельного сервиса:

```bash
cd rag-api-service
docker build -t rag-api-service .
docker run -p 8000:8000 rag-api-service
```

или через локальный Docker Compose (если предусмотрено).

---

## Рекомендации по развёртыванию

**Все сервисы можно запустить на одном сервере (на одном железе).**  
**Однако это не рекомендуется для production.** Для надёжности и масштабируемости лучше разворачивать сервисы на отдельных виртуальных машинах или контейнерах (например, с использованием Kubernetes или Docker Swarm).

---

## Взаимодействие сервисов

В платформе предусмотрено несколько сервисов и компонентов, каждый из которых выполняет свою роль в экосистеме RAG. Все сервисы могут работать на одном сервере, но для надёжности рекомендуется разворачивать их на отдельных виртуальных машинах или контейнерах.

### Как взаимодействуют сервисы?

Общая схема взаимодействия:
- **etl** и **sft-pipeline** подготавливают данные и обучают модели.
- **bi-encoder** индексирует данные для быстрого поиска в Elasticsearch.
- **rag-api-service** использует эти данные для ответа на вопросы пользователей.
- **local-llm-service** используется rag-api-service как один из LLM-клиентов.
- Все сервисы взаимодействуют через DVC (данные и модели), а также очереди сообщений (FastStream) и Elasticsearch.

---

## Сервисы платформы

### rag-api-service
- FastAPI-приложение, предоставляющее REST API для приёма вопросов пользователей, поиска и генерации ответов.
- Использует Elasticsearch для поиска контекста.
- Интегрируется с LLM (GigaChat, Yandex, локальный).
- Поддерживает асинхронную обработку задач через FastStream.

### bi-encoder
- Сервис для векторизации текста и индексации данных.
- Обеспечивает быстрый поиск в Elasticsearch по эмбеддингам.

### etl
- Сервис для обработки и очистки данных (документов на базе которых будет строится RAG).
- Подготавливает данные для обучения моделей.
- Может быть интегрирован с Airflow.

### sft-pipeline
- Пайплайны для обучения моделей.
- Использует Apache Airflow для автоматизации задач.

### local-llm-service
- Сервис для локального развёртывания LLM.
- Используется rag-api-service для генерации ответов, если требуется локальный LLM.

---

## Управление данными и моделями

Используйте DVC для загрузки данных и моделей:

```bash
dvc pull
```

---

## Контрибуция

1. Форкните репозиторий.
2. Создайте новую ветку:
   ```bash
   git checkout -b feature/your-feature
   ```
3. Внесите изменения и закоммитьте:
   ```bash
   git commit -am 'Add your feature'
   ```
4. Отправьте изменения:
   ```bash
   git push origin feature/your-feature
   ```
5. Создайте Pull Request.

---

## Лицензия

Этот проект лицензирован под лицензией MIT. Подробнее см. [LICENSE](LICENSE).
